services:
  mimir-lb:
    image: nginx:1.29-alpine
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - "mimir-1"
      - "mimir-2"
      - "mimir-3"
    ports:
      - 9009:9009
  mimir-1:
    image: &mimir_image registry.smigula.io/docker/grafana/mimir:2.17.1
    container_name: mimir
    restart: unless-stopped
    hostname: mimir-1
    volumes:
      - ./config/mimir/config.yaml:/etc/mimir/config.yaml:ro
      - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - mimir-1-data:/data
    command:
      - --config.file=/etc/mimir/config.yaml
    networks:
      - monitoring
    # depends_on:
    #   - minio # minio is part of different docker compose file...
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2048M
        reservations:
          cpus: "1"
          memory: 1024M

  mimir-2:
    image: *mimir_image
    container_name: mimir
    restart: unless-stopped
    hostname: mimir-2
    volumes:
      - ./config/mimir/config.yaml:/etc/mimir/config.yaml:ro
      - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - mimir-2-data:/data
    command:
      - --config.file=/etc/mimir/config.yaml
    networks:
      - monitoring
    # depends_on:
    #   - minio # minio is part of different docker compose file...
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2048M
        reservations:
          cpus: "1"
          memory: 1024M

  mimir-3:
    image: *mimir_image
    container_name: mimir
    restart: unless-stopped
    hostname: mimir-3
    volumes:
      - ./config/mimir/config.yaml:/etc/mimir/config.yaml:ro
      - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - mimir-3-data:/data
    command:
      - --config.file=/etc/mimir/config.yaml
    networks:
      - monitoring
    # depends_on:
    #   - minio # minio is part of different docker compose file...
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2048M
        reservations:
          cpus: "1"
          memory: 1024M

  loki-init:
    image: &alpine_image registry.smigula.io/docker/alpine:3.22.1
    container_name: loki-init
    volumes:
      - loki-data:/loki
    command: >
      sh -c "

        chown -R 10001:10001 /loki &&
        chmod -R 755 /loki
      "

    networks:
      - monitoring
    restart: "no"
  # Loki for log aggregation
  loki:
    image: registry.smigula.io/docker/grafana/loki:3.5.5
    container_name: loki
    restart: always
    ports:
      - "3100:3100"
    environment:
      - "AWS_SECRET_ACCESS_KEY=LokiP@ss5"
      - "AWS_ACCESS_KEY_ID=lokiuser"
    volumes:
      - ./config/loki/loki-config.yaml:/etc/loki/loki-config.yaml:ro
      - loki-data:/loki
    command: -config.file=/etc/loki/loki-config.yaml
    networks:
      - monitoring
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3100/ready",
        ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    depends_on:
      - loki-init
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 2048M
        reservations:
          cpus: "1"
          memory: 512M
  # Grafana for visualization
  grafana:
    image: registry.smigula.io/docker/grafana/grafana:12.2
    container_name: grafana
    restart: always
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning-datasources.yaml:/etc/grafana/provisioning/provisioning-datasources.yaml:ro
      - ./config/grafana/provisioning-dashboards.yaml:/etc/grafana/provisioning/provisioning-dashboards.yaml:ro
      - ./config/grafana/grafana.ini:/etc/grafana/grafana.ini:ro
      # Explicitly list the dashboards we want to show in the demo. We intentionally exclude dashboards that require
      # Kubernetes metrics (eg. resources or networking) and other services not available in the demo (eg. Grafana Loki).
      - ./config/grafana/dashboards/mimir-alertmanager.json:/var/lib/grafana/dashboards/mimir-alertmanager.json:ro
      - ./config/grafana/dashboards/mimir-compactor.json:/var/lib/grafana/dashboards/mimir-compactor.json:ro
      - ./config/grafana/dashboards/mimir-object-store.json:/var/lib/grafana/dashboards/mimir-object-store.json:ro
      - ./config/grafana/dashboards/mimir-overrides.json:/var/lib/grafana/dashboards/mimir-overrides.json:ro
      - ./config/grafana/dashboards/mimir-queries.json:/var/lib/grafana/dashboards/mimir-queries.json:ro
      - ./config/grafana/dashboards/mimir-reads.json:/var/lib/grafana/dashboards/mimir-reads.json:ro
      - ./config/grafana/dashboards/mimir-ruler.json:/var/lib/grafana/dashboards/mimir-ruler.json:ro
      - ./config/grafana/dashboards/mimir-tenants.json:/var/lib/grafana/dashboards/mimir-tenants.json:ro
      - ./config/grafana/dashboards/mimir-top-tenants.json:/var/lib/grafana/dashboards/mimir-top-tenants.json:ro
      - ./config/grafana/dashboards/mimir-writes.json:/var/lib/grafana/dashboards/mimir-writes.json:ro
    # environment:
    #   - "GF_PLUGINS_PREINSTALL=grafana-clock-panel, grafana-simple-json-datasource"
    env_file:
      - .grafana-secrets.env
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
  dozzle:
    container_name: dozzle
    image: registry.smigula.io/docker/amir20/dozzle:v8
    # secrets:
    #   - source: users
    #     target: /data/users.yml
    volumes:
      - /run/user/1000/docker.sock:/var/run/docker.sock
      - dozzle-data:/data
    ports:
      - 9080:9080
    environment:
      - DOZZLE_NO_ANALYTICS=true
      - DOZZLE_ADDR=:9080
      - DOZZLE_HOSTNAME=dozzle.smigula.io
      - DOZZLE_LEVEL=debug
      - DOZZLE_AUTH_PROVIDER=forward-proxy
    restart: unless-stopped
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 256M
  # cAdvisor for container metrics in rootless mode
  cadvisor:
    image: registry.smigula.io/gcr/cadvisor/cadvisor:v0.52.0
    container_name: cadvisor
    restart: unless-stopped
    ports:
      - "9338:8080"
    volumes:
      - /:/rootfs:ro
      - /sys:/sys:ro
      - /sys/fs/cgroup:/sys/fs/cgroup:ro
      - /dev/disk/:/dev/disk:ro
      - /run/user/1000:/run/user/1000:ro
      - ${HOME}/.local/share/docker/:/var/lib/docker:ro
    devices:
      - /dev/kmsg:/dev/kmsg
    privileged: true
    command:
      - --housekeeping_interval=10s
      - --docker_only=true
      - --disable_metrics=percpu,sched,tcp,udp,disk,diskIO,hugetlb,referenced_memory,cpu_topology,resctrl
      - --store_container_labels=true
      - --docker=unix:///run/user/1000/docker.sock
      - --env_metadata_whitelist=CONTAINER_NAME,CONTAINER_IMAGE
      - --raw_cgroup_prefix_whitelist=/user.slice,/user.slice/user-1000.slice/user@1000.service,/user.slice/user-1000.slice/session-2.scope,/user.slice/user-1000.slice/session-7.scope,/user.slice/user-1000.slice/session-9.scope
      - --enable_load_reader=false
      - --max_procs=4
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 4098M
        reservations:
          cpus: "0.25"
          memory: 512M
  # Grafana Alloy for observability data collection
  alloy:
    image: registry.smigula.io/docker/grafana/alloy:v1.10.2
    container_name: alloy
    restart: unless-stopped
    volumes:
      - /run/user/1000/docker.sock:/var/run/docker.sock:ro
      - ./config/alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /mnt/data/logs/traefik:/var/log/traefik:ro
      - alloy-data:/var/lib/alloy
    command:
      - run
      - /etc/alloy/config.alloy
      - --storage.path=/var/lib/alloy/data
      - --server.http.listen-addr=0.0.0.0:12345
    ports:
      - "12345:12345"
    env_file:
      - .alloy-secrets.env
    networks:
      - monitoring
      - registry
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 8192M
        reservations:
          cpus: "1"
          memory: 1024M
  # Tempo runs as user 10001, and docker compose creates the volume as root.
  # As such, we need to chown the volume in order for Tempo to start correctly.
  tempo-init:
    image: *alpine_image
    container_name: tempo-init
    user: root
    command: >
      sh -c "
        chown -R 10001:10001 /var/tempo &&
        chmod -R 755 /var/tempo
      "

    volumes:
      - tempo-data:/var/tempo
    networks:
      - monitoring
    restart: "no"
  tempo:
    image: registry.smigula.io/docker/grafana/tempo:2.8.2
    container_name: tempo
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ../shared/tempo.yaml:/etc/tempo.yaml:ro
      - tempo-data:/var/tempo
    ports:
      - "3200:3200" # Tempo query endpoint
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver
    depends_on:
      - tempo-init
    networks:
      - monitoring
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1024M
        reservations:
          cpus: "0.25"
          memory: 256M

  # troubleshooting pod
  troubleshooting:
    image: registry.smigula.io/docker/nicolaka/netshoot:v0.14
    container_name: troubleshooting
    command: sh
    stdin_open: true
    tty: true
    networks:
      - monitoring
      - registry

# secrets:
#   users:
#     file: users.yml
volumes:
  mimir-1-data:
    driver: local
    driver_opts:
      type: none
      device: /mnt/data/mimir-1
      o: bind
  mimir-2-data:
    driver: local
    driver_opts:
      type: none
      device: /mnt/data/mimir-2
      o: bind
  mimir-3-data:
    driver: local
    driver_opts:
      type: none
      device: /mnt/data/mimir-3
      o: bind
  grafana-data:
    driver: local
    driver_opts:
      type: none
      device: /mnt/data/grafana
      o: bind
  loki-data:
    driver: local
  dozzle-data:
    driver: local
  alloy-data:
    driver: local
  tempo-data:
    driver: local

networks:
  monitoring:
    external: true
  registry:
    external: true
    # traefik:
    #   external: true
